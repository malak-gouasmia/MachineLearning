{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M39mHfHvKYvt"
      },
      "source": [
        "# 2CS SIQ2-SIL2 TP04. Naïve Bayes\n",
        "\n",
        "Dans ce TP, nous allons traiter Naïve Bayes. C'est le seul algorithme dans notre programme qui crée un modèle génératif (en plus des auto-encodeurs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6OemfHnKYwE"
      },
      "source": [
        "- **Binôme 01** : TOUHAR Afnane\n",
        "- **Binôme 02** : GOUASMIA Malak \n",
        "- **Groupe** : SIL2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXWVWMBrKYwG",
        "outputId": "a57587fe-ba5b-4b08-ff29-15fa2a31a4d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.22.4', '1.5.3', '3.7.1')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import matplotlib\n",
        "import numpy             as np\n",
        "import pandas            as pd \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "np        .__version__ , \\\n",
        "pd        .__version__ , \\\n",
        "matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5a9XPkpKKYwJ"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsW6r1AiKYwK"
      },
      "source": [
        "**RAPPEL**\n",
        "\n",
        "Tout le monde connait le théorème de Bayes pour calculer la probabilité conditionnelle d'un évennement $A$ sachant un autre $B$ (si vous ne le connaissez pas; vous n'appartenez pas à tout le monde) : \n",
        "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
        "\n",
        "Pour appliquer ce théorème sur un problème d'appentissage automatique, l'idée est simple ; Etant donné une caractéristique $f$ et la sortie $y$ qui peut avoir la classe $c$ : \n",
        "- Remplacer $A$ par $y=c$\n",
        "- Remplacer $B$ par $f$ \n",
        "On aura l'équation : \n",
        "$$ P(y=c|f) = \\frac{P(y=c)P(f|y=c)}{P(f)}$$\n",
        "\n",
        "On appelle : \n",
        "- $P(y=c|f)$ postérieure \n",
        "- $P(y=c)$ antérieure\n",
        "- $P(f|y=c)$ vraisemblance\n",
        "- $P(f)$ évidence \n",
        "\n",
        "Ici, on estime la probablité d'une classe $c$ sachant une caractéristique $f$ en utilisant des données d'entrainement. Maintenant, on veut estimer la probabilité d'une classe $c$ sachant un vecteur de caractéristiques $\\overrightarrow{f} = \\{f_1, ..., f_L\\}$ : \n",
        "$$ P(y=c|\\overrightarrow{f}) = \\frac{P(y=c)P(\\overrightarrow{f}|y=c)}{P(f)}$$\n",
        "\n",
        "Etant donnée plusieurs classes $c_j$, la classe choisie $\\hat{c}$ est celle avec la probabilité maximale \n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k|\\overrightarrow{f})$$\n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\frac{P(y=c_k)P(\\overrightarrow{f}|y=c_k)}{P(f)}$$\n",
        "On supprime l'évidence pour cacher le crime : $P(f)$ ne dépend pas de $c_k$ et elle est postive, donc ça ne va pas affecter la fonction $\\max$.\n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k)P(\\overrightarrow{f}|y=c_k)$$\n",
        "\n",
        "Pour calculer $P(\\overrightarrow{f}|y=c_k)$, on va utiliser une properiété naïve (d'où vient le nom Naive Bayes) : on suppose l'indépendence conditionnelle entre les caractéristiques $f_j$. \n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k) \\prod\\limits_{f_j \\in \\overrightarrow{f}} P(f_j|y=c_k)$$\n",
        "\n",
        "Pour éviter la disparition de la probabilité (multiplication et représentation de virgule flottante sur machine), on transforme vers l'espace logarithme.\n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKDOXKyHKYwM"
      },
      "source": [
        "## I. Réalisation des algorithmes\n",
        "\n",
        "Pour estimer la vraisemblance, il existe plusieurs modèles (lois):\n",
        "- **Loi multinomiale :** pour les caracétristiques nominales\n",
        "- **Loi de Bernoulli :** lorsqu'on est interressé par l'apparence d'une caractéristique ou non (binaire)\n",
        "- **Loi normale :** pour les caractéristiques numériques\n",
        "\n",
        "Dans ce TP, nous allons implémenter Naive Bayes pour les caractéristiques nominales (loi multinomiale). \n",
        "Dans notre modèle, nous voulons stocker les statistiques et pas les probabilités. \n",
        "L'intérêt est de faciliter la mise à jours des statistiques (si par exemple, nous avons un autre dataset et nous voulons enrichir le modèle ; dans e cas, il suffit d'ajouter les statistiques du nouveau dataset)\n",
        "\n",
        "Ici, nous allons utiliser le dataset \"jouer\" (utilisé dans la plupart des cours) contenant des caractéristiques nominales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HRMhsaLKYwO",
        "outputId": "b260809d-9702-47bd-ae77-e3b90b6f6368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        temps temperature humidite vent jouer\n",
            "0   ensoleile      chaude    haute  non   non\n",
            "1   ensoleile      chaude    haute  oui   non\n",
            "2     nuageux      chaude    haute  non   oui\n",
            "3    pluvieux       douce    haute  non   oui\n",
            "4    pluvieux     fraiche  normale  non   oui\n",
            "5    pluvieux     fraiche  normale  oui   non\n",
            "6     nuageux     fraiche  normale  oui   oui\n",
            "7   ensoleile       douce    haute  non   non\n",
            "8   ensoleile     fraiche  normale  non   oui\n",
            "9    pluvieux       douce  normale  non   oui\n",
            "10  ensoleile       douce  normale  oui   oui\n",
            "11    nuageux       douce    haute  oui   oui\n",
            "12    nuageux      chaude  normale  non   oui\n",
            "13   pluvieux       douce    haute  oui   non\n"
          ]
        }
      ],
      "source": [
        "jouer   = pd.read_csv('data/jouer.csv')\n",
        "\n",
        "X_jouer = jouer.iloc[:, :-1].values # Premières colonnes \n",
        "Y_jouer = jouer.iloc[:,  -1].values # Dernière colonne \n",
        "\n",
        "# Afficher le dataset \"jouer\"\n",
        "print(jouer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NBBF0Cq9sGNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d34837-507a-49f2-9ff8-d11f07159a0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNDKgwhGKYwQ"
      },
      "source": [
        "### I.1. Entraînement de la probabilité antérieure\n",
        "\n",
        "Etant donné le vecteur de sortie $Y$, la probabilité de chaque classe (différentes valeurs de $Y$) est calulée comme :\n",
        "\n",
        "$$p(c_k) = \\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
        "\n",
        "\n",
        "La fonction doit récupérer des statistiques afin de pouvoir calculer la probabilité antérieure de chaque classe. Donc, elle doit retourner  :\n",
        "- Un vecteur contenant les noms des classes\n",
        "- Un vecteur contenant les nombres d'occurrences de chaque classe dans le premier vecteur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiWr5t9LKYwQ",
        "outputId": "42c6fd76-4589-4f14-a508-1a463154a32f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['non', 'oui'], dtype=object), array([5, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: Stastistiques sur la probabilité antérieure\n",
        "def stat_anterieure(Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]: \n",
        "    cls  = np.unique(Y) # le vecteur des classes\n",
        "    freq = []\n",
        "    # compléter à partir d'ici\n",
        "    cls, freq = np.unique(Y, return_counts=True)\n",
        "    return cls, np.array(freq)\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# (array(['non', 'oui'], dtype=object), array([5, 9]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "stat_anterieure(Y_jouer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EnFYCPCKYwS"
      },
      "source": [
        "### I.2. Entraînement de la probabilité de vraissemblance (loi multinomiale)\n",
        "\n",
        "Notre modèle doit garder le nombre des différentes valeurs d'une caractéristique $A$ et le nombre de ces valeurs dans chaque classe.\n",
        "Donc, étant donné un vecteur d'une caractéristique $A= X[:,j]$, un autre des $Y$ et un $C$ contenant la liste des classes, la fonction d'entraînement doit retourner : \n",
        "- $V$ : un vecteur contenant les différentes catégories de $A$ (c'est déjà fait)\n",
        "- Une matrice contenant le nombre d'occurrences de chaque catégorie de $V$ dans chaque classe  : \n",
        "   - Les lignes représentent les catégories $v \\in V$ de la caréctéristique $A$\n",
        "   - Les colonnes représentent les classes $c \\in C$ de $Y$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ2-yaFhKYwT",
        "outputId": "a39f3eee-5aec-429c-b526-e705f59c713f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
              " array([[3, 2],\n",
              "        [0, 4],\n",
              "        [2, 3]], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# TODO: Statistiques de vraissemblance (une seule caractéristique)\n",
        "def stat_vraissemblance_1(A: np.ndarray, \n",
        "                          Y: np.ndarray, \n",
        "                          C: np.ndarray\n",
        "                         ) -> Tuple[np.ndarray, np.ndarray]: \n",
        "    freq = []\n",
        "    V = np.unique(A) # Catégories de la caractéristique A\n",
        "    # compléter à partir d'ici\n",
        "\n",
        "    freq = np.zeros((len(V), len(C)), dtype=np.int32) \n",
        "    for i, c in enumerate(C):\n",
        "        W = A[Y == c] \n",
        "        for j, v in enumerate(V):\n",
        "            freq[j, i] = np.sum(W == v)\n",
        "    return V, np.array(freq)\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# (array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
        "#  array([[3, 2],\n",
        "#         [0, 4],\n",
        "#         [2, 3]]))\n",
        "#---------------------------------------------------------------------\n",
        "C_t = np.array(['non', 'oui'])\n",
        "stat_vraissemblance_1(X_jouer[:, 0], Y_jouer, C_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTKYeZZAKYwU"
      },
      "source": [
        "### I.3. Entraînement loi multinomiale\n",
        "\n",
        "**Rien à programmer ici**\n",
        "\n",
        "Notre modèle ($\\theta_{X, C}$) doit garder des statistiques sur les classes et aussi sur chaque catégorie de chaque caractéristique. Pour ce faire, nous allons représenter $\\theta$ comme un vecteur : \n",
        "- $\\theta[N+1]$ est un vecteur de $N$ éléments représentant des statistiques sur chaque caractéristique $j$, plus un élément (le dernier) pour les statistiques sur les classes.\n",
        "- Chaque élément est un dictionnaire (HashMap en Java)\n",
        "- Un élément des caractéristiques contient deux clés : \n",
        "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique\n",
        "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe\n",
        "- Un élément des classes contient deux clés : \n",
        "    - **cls** : pour récupérer la liste des noms des classes\n",
        "    - **freq**: pour récupérer la liste des fréquences de chaque classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnQ8jsi1KYwV",
        "outputId": "7361c681-9263-487c-e903-c65f34816008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
              "  'freq': array([[3, 2],\n",
              "         [0, 4],\n",
              "         [2, 3]], dtype=int32)},\n",
              " {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
              "  'freq': array([[2, 2],\n",
              "         [2, 4],\n",
              "         [1, 3]], dtype=int32)},\n",
              " {'val': array(['haute', 'normale'], dtype=object),\n",
              "  'freq': array([[4, 3],\n",
              "         [1, 6]], dtype=int32)},\n",
              " {'val': array(['non', 'oui'], dtype=object),\n",
              "  'freq': array([[2, 6],\n",
              "         [3, 3]], dtype=int32)},\n",
              " {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# La fonction qui entraine Théta sur plusieurs caractéristiques\n",
        "# Rien à programmer ici\n",
        "# Notre théta est une liste des dictionnaires;\n",
        "# chaque dictionnaire contient la liste des catégories et la matrice des fréquences dela caractéristique respective à la colonne de X\n",
        "# On ajoute les statistiques antérieures des classes à la fin de résultat\n",
        "def entrainer_multi(X: np.ndarray, \n",
        "                    Y: np.ndarray\n",
        "                   ) -> np.ndarray: \n",
        "    \n",
        "    Theta   = []\n",
        "    \n",
        "    stats_c = {}\n",
        "    stats_c['cls'], stats_c['freq'] =  stat_anterieure(Y)\n",
        "    \n",
        "    for j in range(X.shape[1]): \n",
        "        stats = {}\n",
        "        stats['val'], stats['freq'] =  stat_vraissemblance_1(X[:, j], Y, stats_c['cls'])\n",
        "        Theta.append(stats)\n",
        "    \n",
        "    Theta.append(stats_c)\n",
        "    return Theta\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# [{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
        "#   'freq': array([[3, 2],\n",
        "#          [0, 4],\n",
        "#          [2, 3]])},\n",
        "#  {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
        "#   'freq': array([[2, 2],\n",
        "#          [2, 4],\n",
        "#          [1, 3]])},\n",
        "#  {'val': array(['haute', 'normale'], dtype=object),\n",
        "#   'freq': array([[4, 3],\n",
        "#          [1, 6]])},\n",
        "#  {'val': array(['non', 'oui'], dtype=object),\n",
        "#   'freq': array([[2, 6],\n",
        "#          [3, 3]])},\n",
        "#  {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]\n",
        "#---------------------------------------------------------------------\n",
        "Theta_jouer = entrainer_multi(X_jouer, Y_jouer)\n",
        "\n",
        "Theta_jouer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRmx69mKYwW"
      },
      "source": [
        "### I.4. Estimation de la probabilité de vraissemblance (loi multinomiale)\n",
        "L'équation pour estimer la vraisemblance \n",
        "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
        "\n",
        "\n",
        "Dans le cas d'une valeur $v$ qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donnée mais ui existe dans le dataset de test, nous aurons une probabilité nulle. \n",
        "Afin de régler ce problème, nous pouvons appliquer une fonction de lissage qui attribue une petite probabilité aux données non vues dans l'entraînement. \n",
        "Le lissage que nous allons utiliser est celui de Lidstone. \n",
        "Lorsque $\\alpha = 1$, il est appelé lissage de Laplace.\n",
        "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}| + \\alpha}{|\\{y = c_k\\}| + \\alpha * |V|}$$\n",
        "Où: \n",
        "- $\\alpha$ est une valeur donnée \n",
        "- $V$ est l'ensemble des différentes valeurs de $f_j$ (le vocabulaire; les catégories)\n",
        "\n",
        "Etant donné : \n",
        "- $\\theta_j$ les paramètres de la caractéristique $j$ représentées comme dictionnaire\n",
        "    - **val** : pour récupérer la liste des noms des catégories de la caractéristique (vocabulaire $V$)\n",
        "    - **freq**: pour récupérer une matrice représentant la fréquence de chaque caractéristique dans chaque classe. C'est une matrice $|V|\\times|C|$\n",
        "- $v$ la valeur de la caractéristique $j$ utilisée pour calculer les probabilités\n",
        "- $\\theta_c$ les paramètres des classes $C$ représentées comme dictionnaire\n",
        "    - **cls** : pour récupérer la liste des noms des classes\n",
        "    - **freq**: pour récupérer la liste des fréquences des classes\n",
        "    \n",
        "Cette fonction doit retourner : \n",
        "- Une liste $P[|C|]$ contenant les probabilités de la catégorie $v$ de $X_j$ sur toutes les classes $C$ \n",
        "- Elle doit prendre en considération le cas où la valeur $v$ n'existe pas dans le modèle entraîné"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b06oGfMVKYwX",
        "outputId": "5f4e8dd7-083b-4b86-f4c8-a7df7423d1f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# TODO: Calculer la vraissamblance d'une valeur donnée\n",
        "def P_vraiss_multi(Theta_j: Dict[str, np.ndarray], \n",
        "                   Theta_c: Dict[str, np.ndarray], \n",
        "                   v      : str, \n",
        "                   alpha  : float = 0.\n",
        "                  ) -> Tuple[np.ndarray, np.ndarray]: \n",
        "    \n",
        "    #une liste des indices où se trouve la valeur v dans Theta_j[\"val\"]\n",
        "    ind = np.where(Theta_j['val'] == v)[0] \n",
        "    # Récupérer la matrice de fréquences des caractéristiques pour chaque classe\n",
        "    Matfreq = Theta_j['freq']\n",
        "    # Récupérer la liste des fréquences des classes\n",
        "    freqClas = Theta_c['freq']\n",
        "    # compléter à partir d'ici\n",
        "    probas = np.zeros(len(Theta_c['cls']))\n",
        "    # Calculer les probabilités pour chaque classe\n",
        "    for i, c in enumerate(Theta_c['cls']):\n",
        "        # Récupérer la fréquence de la valeur v pour la classe c\n",
        "        if ind.size == 0: # Si la valeur v n'existe pas dans le dataset d'entraînement\n",
        "            freq_jc_vc = 0\n",
        "        else:\n",
        "            freq_jc_vc = Matfreq[ind, i]\n",
        "        \n",
        "        # Calculer la probabilité en utilisant le lissage de Lidstone\n",
        "        probas[i] = (freq_jc_vc + alpha) / (freqClas[i] + alpha * len(Theta_j['val']))\n",
        "        \n",
        "    return probas\n",
        "   \n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# (array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))\n",
        "#---------------------------------------------------------------------\n",
        "# Calcul :\n",
        "# La probabilité de jouer si temps = pluvieux \n",
        "# P(temps = pluvieux | jouer=oui) = (nbr(temps=pluvieux et jouer=oui)+alpha)/(nbr(jour=oui) + alpha * nbr_diff(temps)))\n",
        "# P(temps = pluvieux | jouer=oui) = (3 + 0)/(9 + 0) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
        "# P(temps = pluvieux | jouer=oui) = 4/12 ==> 0.33333333333333333333333333333333333~\n",
        "\n",
        "# La probabilité de jouer si temps = neigeux \n",
        "# P(temps = neigeux | jouer=oui) = (nbr(temps=neigeux et jouer=oui)+alpha)/(nbr(jouer=oui) + alpha * nbr_diff(temps)))\n",
        "# P(temps = neigeux | jouer=oui) = (0 + 1)/(9 + 3) ==> 3 est le nombre de différentes valeurs de temps (entrainnement)\n",
        "# P(temps = neigeux | jouer=oui) = 1/13 ==> 0.0833333333333333333333333333333333333~\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'pluvieux'), \\\n",
        "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'neigeux', alpha=1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C89-zLF4KYwZ"
      },
      "source": [
        "### I.5. Prédiction de la classe (loi multinomiale)\n",
        "Revenons maintenant à notre équation de prédiction \n",
        "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
        "\n",
        "- On doit prédire un seule échantillon $x$. \n",
        "- La fonction doit retourner un vecteur des log-probabilité des classes\n",
        "- Si anter=false donc on n'utilise pas la probabilité antérieure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BIvd7tGKYwZ",
        "outputId": "011ace21-d6e0-418e-a3f7-b4f6b8a0ae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TODO: Prediction of log probabilities\n",
        "def predire(x: np.ndarray, Theta: List[Dict[str, np.ndarray]], alpha: float = 1., anter: bool = True) -> float:\n",
        "    p = np.zeros(2)\n",
        "    if anter:\n",
        "        p = np.log(Theta[-1]['freq'] / np.sum(Theta[-1]['freq'][:]))\n",
        "    for i in range(len(Theta)-1):\n",
        "        p += np.log(P_vraiss_multi(Theta[i], Theta[-1], x[i], alpha))\n",
        "    return p\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# (array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))\n",
        "#---------------------------------------------------------------------\n",
        "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer), \\\n",
        "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer, anter=False) "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6XYKAPP85eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpD1JRCOKYwa"
      },
      "source": [
        "### I.6. Regrouper en une classe (loi multinomiale)\n",
        "\n",
        "**Rien à programmer ici**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPbrDgPKKYwa",
        "outputId": "4cb59ebc-c373-45d5-8160-f367489ec541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oui', 'non']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "class NBMultinom(object): \n",
        "    \n",
        "    def __init__(self, alpha=1.): \n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def entrainer(self, X, Y):\n",
        "        self.Theta = entrainer_multi(X, Y)\n",
        "    \n",
        "    def predire(self, X, anter=True, prob=False): \n",
        "        Y_pred = []\n",
        "        cls = self.Theta[-1]['cls']\n",
        "        for i in range(len(X)): \n",
        "            log_prob = predire(X[i,:], self.Theta, alpha=self.alpha, anter=anter)\n",
        "            if prob:\n",
        "                Y_pred.append(np.max(log_prob))\n",
        "            else:\n",
        "                Y_pred.append(cls[np.argmax(log_prob)])\n",
        "        return Y_pred\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# ['oui', 'non']\n",
        "#---------------------------------------------------------------------\n",
        "notre_modele = NBMultinom()\n",
        "notre_modele.entrainer(X_jouer, Y_jouer)\n",
        "X_test = np.array([\n",
        "    ['neigeux', 'fraiche', 'normale', 'oui'],\n",
        "    ['neigeux', 'fraiche', 'haute'  , 'oui']\n",
        "])\n",
        "notre_modele.predire(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LlcU8HEKYwb"
      },
      "source": [
        "## II. Application et analyse\n",
        "\n",
        "**Il n'y a rien à programmer ici.**\n",
        "\n",
        "Le but de cette section est de mener des expérimentations afin de bien comprendre les concepts vus dans le cours.\n",
        "Aussi, elle nous assiste à comprendre l'effet des différents paramètres.\n",
        "En plus, la discussion des différentes expérimentations peut améliorer l'aspect analytique chez l'étudient.\n",
        "\n",
        "### II.1. Probabilité antérieure \n",
        "\n",
        "Nous voulons tester l'effet de la probabilité antérieure.\n",
        "Pour ce faire, nous avons entraîné deux modèles :\n",
        "1. Avec probabilité antérieure\n",
        "1. Sans probabilité antérieure (Il considère une distribution uniforme des classes)\n",
        "\n",
        "Pour tester si les modèles ont bien s'adapter au dataset d'entraînement, nous allons les tester sur le même dataset et calculer le rapport de classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeSHUL3eKYwc",
        "outputId": "b409a042-6d5d-465f-d35f-02794fce52a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avec probabilité antérieure (a priori)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         non       1.00      0.80      0.89         5\n",
            "         oui       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Sans probabilité antérieure (a priori)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         non       0.67      0.80      0.73         5\n",
            "         oui       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.79        14\n",
            "   macro avg       0.77      0.79      0.78        14\n",
            "weighted avg       0.80      0.79      0.79        14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# AVEC Scikit-learn\n",
        "# ===================\n",
        "from sklearn.naive_bayes   import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics       import classification_report\n",
        "\n",
        "nb_avec     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
        "nb_sans     = CategoricalNB(alpha=1.0, fit_prior=False)\n",
        "\n",
        "enc         = OrdinalEncoder()\n",
        "X_jouer_enc = enc.fit_transform(X_jouer)\n",
        "nb_avec.fit(X_jouer_enc, Y_jouer)\n",
        "nb_sans.fit(X_jouer_enc, Y_jouer)\n",
        "\n",
        "Y_pred_avec = nb_avec.predict(X_jouer_enc)\n",
        "Y_pred_sans = nb_sans.predict(X_jouer_enc)\n",
        "\n",
        "# AVEC notre modèle (juste pour voir comment l'utiliser)\n",
        "# =======================================================\n",
        "#notre_modele = NBMultinom()\n",
        "#notre_modele.entrainer(X_jouer, Y_jouer)\n",
        "#Y_notre_ant = notre_modele.predire(X_jouer)\n",
        "#Y_notre_sans_ant = notre_modele.predire(X_jouer, anter=False) \n",
        "\n",
        "# Le rapport de classification\n",
        "\n",
        "\n",
        "print( 'Avec probabilité antérieure (a priori)'  )\n",
        "print(classification_report(Y_jouer, Y_pred_avec))\n",
        "\n",
        "print( 'Sans probabilité antérieure (a priori)'  )\n",
        "print(classification_report(Y_jouer, Y_pred_sans))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-BR9q_9KYwc"
      },
      "source": [
        "**TODO: Analyser les résultats**\n",
        "    \n",
        "- Que remarquez-vous ?\n",
        "- Est-ce que la probabilité antérieure est importante dans ce cas ?\n",
        "- Comment cette probabilité affecte le résultat ?\n",
        "- Quand est-ce que nous sommes sûrs que l'utilisation de cette probabilité est inutile ?\n",
        "\n",
        "**Réponse**\n",
        "\n",
        "- En comparant les deux rapports de classification, nous pouvons remarquer que le modèle qui utilise la probabilité antérieure (a priori) a une précision plus élevée et un score F1 plus élevé pour les deux classes. En outre, le modèle avec la probabilité antérieure a une précision de 100% pour la classe \"non\", tandis que le modèle sans la probabilité antérieure a une précision de seulement 67%.\n",
        "- D'apres la reponse précédente , on peut déduire  que la probabilité antérieure est importante dans ce cas,car elle  est utilisée pour informer le modèle de la probabilité de chaque classe avant de voir les données d'entraînement.\n",
        "- La probabilité antérieure affecte la façon dont le modèle calcule les probabilités pour chaque classe. Lorsqu'elle est bien choisie, elle peut améliorer les performances du modèle en évitant le sur-apprentissage et en aidant à généraliser les résultats. Cependant, si elle est mal choisie, elle peut affecter négativement les performances du modèle.\n",
        "- L'utilisation de la probabilité antérieure est souvent considérée comme inutile lorsque les données sont suffisamment représentatives et que les classes sont équilibrées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Ll4XFDKYwc"
      },
      "source": [
        "### II.2. Lissage\n",
        "\n",
        "Nous voulons tester l'effet de lissage de Lidstone.\n",
        "Pour ce faire, nous avons entraîné trois modèles : \n",
        "1. alpha = 1 (lissage de Laplace)\n",
        "1. alpha = 0.5\n",
        "1. alpha = 0 (sans lissage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGcOJ40KYwd",
        "outputId": "17bd8132-2a84-4570-d029-b62e136396c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         non       1.00      0.80      0.89         5\n",
            "         oui       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         non       1.00      0.80      0.89         5\n",
            "         oui       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         non       1.00      0.80      0.89         5\n",
            "         oui       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
        "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
        "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
        "\n",
        "NBC_10.fit( X_jouer_enc,   Y_jouer )\n",
        "NBC_05.fit( X_jouer_enc,   Y_jouer )\n",
        "NBC_00.fit( X_jouer_enc,   Y_jouer )\n",
        "\n",
        "Y_10   = NBC_10.predict(X_jouer_enc)\n",
        "Y_05   = NBC_05.predict(X_jouer_enc)\n",
        "Y_00   = NBC_00.predict(X_jouer_enc)\n",
        "\n",
        "\n",
        "print(          'Alpha = 1.0'             )\n",
        "print(classification_report(Y_jouer, Y_10))\n",
        "\n",
        "print(          'Alpha = 0.5'             )\n",
        "print(classification_report(Y_jouer, Y_05))\n",
        "\n",
        "print(          'Alpha = 0.0'             )\n",
        "print(classification_report(Y_jouer, Y_00))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8cE5WdyKYwe"
      },
      "source": [
        "**TODO: Analyser les résultats**\n",
        "\n",
        "- Que remarquez-vous ?\n",
        "- Est-ce que le lissage affecte la performance dans ce cas ? Pourquoi ?\n",
        "- Pourquoi Scikit-learn n'accepte pas la valeur $\\alpha=0$ et affiche une alerte \"UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\" ?\n",
        "- Quelle est l'intérêt du lissage (dans le cas général) ?\n",
        "\n",
        "**Réponse**\n",
        "\n",
        "- En analysant les résultats, nous remarquons que les trois modèles ont des performances similaires, avec des scores de précision, de rappel et de f1-score élevés pour les deux classes (non et oui).\n",
        "- D'apres ce qu'on a remarqué,il est clair que dans ce cas spécifique, le lissage n'a pas affecté les performances du modèle.Cela peut être dû au fait que le jeu de données est relativement petit et simple, avec seulement deux classes et peu de caractéristiques.\n",
        "- Le lissage de Laplace (ou Lidstone) est une technique courante pour éviter les problèmes de probabilités nulles dans les modèles de classification naïve bayésienne. Cette technique ajoute une petite constante, appelée alpha, à toutes les fréquences de comptage pour éviter que certaines probabilités ne soient égales à zéro.Lorsque alpha est égal à zéro, cela signifie qu'aucun lissage n'est effectué, ce qui peut conduire à des probabilités nulles et à des erreurs numériques dans les calculs. Pour éviter ces erreurs, Scikit-learn fixe la valeur minimale d'alpha à 1e-10.\n",
        "- Dans le cas général, l'intérêt du lissage est de régulariser les estimations des probabilités conditionnelles pour des classes ou des attributs qui peuvent avoir peu d'exemples dans l'ensemble d'entraînement. Le lissage permet de donner une estimation plus robuste des probabilités et ainsi d'améliorer la généralisation du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG9GOI3cKYwe"
      },
      "source": [
        "### II.3. Comparaison avec d'autres algorithmes\n",
        "\n",
        "Naive Bayes est un algorithme puissant lorsqu'il s'agit de classer les documents textuels ; nous voulons tester cette information avec la détection de spam. \n",
        "Le dataset utilisé est [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
        "Chaque message du dataset doit être représenté sous forme d'un modèle \"Sac à mots\" (BoW : Bag of Words).\n",
        "Dans l'entraînement, les différents mots qui s'apparaissent dans les messages (vocabulaire) sont considérés comme des caractéristiques. \n",
        "Donc, pour chaque message, la valeur de la caractéristique est la fréquence du mot dans le message. \n",
        "Par exemple, si le mot \"good\" apparait 3 fois dans le message, donc la caractéristique \"good\" aura la valeur 3 dans ce message.\n",
        "\n",
        "Notre implémentation n'est pas adéquate pour la nature de ce problème. \n",
        "Dans Scikit-learn, [sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) est similaire à notre implémentation. \n",
        "L'algorithme adéquat pour ce type de problème est [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
        "Les algorithmes comparés :\n",
        "1. Naive Bayes (Loi Multinomiale)\n",
        "1. Naive Bayes (Loi Gaussienne)\n",
        "1. Regression logistique \n",
        "1. Arbres de decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fVLpyrsrKYwe",
        "outputId": "680e35f2-de4a-44fb-d559-3ed6b1bf08be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               texte classe\n",
              "0  Go until jurong point, crazy.. Available only ...    ham\n",
              "1                      Ok lar... Joking wif u oni...    ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
              "3  U dun say so early hor... U c already then say...    ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...    ham"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0dfce4f3-80ab-47d7-a3f0-540f9349b6dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texte</th>\n",
              "      <th>classe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dfce4f3-80ab-47d7-a3f0-540f9349b6dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0dfce4f3-80ab-47d7-a3f0-540f9349b6dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0dfce4f3-80ab-47d7-a3f0-540f9349b6dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# lire le dataset\n",
        "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
        "# renomer les caractéristiques : texte et classe\n",
        "messages = messages.rename(columns={'v1': 'classe', 'v2': 'texte'})\n",
        "# garder seulement ces deux caractéristiques\n",
        "messages = messages.filter(['texte', 'classe'])\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljq5i3KuKYwf",
        "outputId": "f6925651-1dc4-469e-aa4d-147ae6654045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fin\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection         import train_test_split\n",
        "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model            import LogisticRegression\n",
        "from sklearn.tree                    import DecisionTreeClassifier\n",
        "from sklearn.metrics                 import precision_score, recall_score\n",
        "import timeit\n",
        "\n",
        "\n",
        "modeles = [\n",
        "    MultinomialNB(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(solver='lbfgs') ,\n",
        "    #solver=sag est plus lent; donc j'ai choisi le plus rapide\n",
        "    DecisionTreeClassifier()\n",
        "]\n",
        "\n",
        "temps_train = []\n",
        "temps_test  = []\n",
        "rappel      = []\n",
        "precision   = []\n",
        "\n",
        "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['texte'] ,\n",
        "                                                        messages['classe'],\n",
        "                                                        test_size    = 0.2, \n",
        "                                                        random_state = 0  )\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
        "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
        "\n",
        "\n",
        "for modele in modeles:\n",
        "    # ==================================\n",
        "    # ENTRAINEMENT \n",
        "    # ==================================\n",
        "    temps_debut = timeit.default_timer()\n",
        "    modele.fit(X_train, Y_train)\n",
        "    temps_train.append(timeit.default_timer() - temps_debut)\n",
        "    \n",
        "    # ==================================\n",
        "    # TEST \n",
        "    # ==================================\n",
        "    temps_debut = timeit.default_timer()\n",
        "    Y_pred      = modele.predict(X_test)\n",
        "    temps_test.append(timeit.default_timer() - temps_debut)\n",
        "    \n",
        "    # ==================================\n",
        "    # PERFORMANCE \n",
        "    # ==================================\n",
        "    # Ici, nous considérons une classification binaire avec une seule classe \"spam\" \n",
        "    # le classifieur ne sera pas jugé par sa capacité de détecter les non spams\n",
        "    precision.append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
        "    rappel   .append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
        "\n",
        "    \n",
        "print('Fin') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgv7MF1BKYwg"
      },
      "source": [
        "#### II.3.1. Temps d'entraînement et de test\n",
        "\n",
        "Combien de temps chaque algorithme prend pour entrainer le même dataset d'entrainement et combien de temps pour tester le même dataset de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "UsO_x_96KYwg",
        "outputId": "1b6c95c9-00db-4b0e-8194-582f24d97a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Algorithme  Temps d'entrainement  Temps de test\n",
              "0  Naive Bayes Multinomial (NBM)              0.976525       0.061037\n",
              "1     Naive Bayes Gaussien (NBG)              0.817354       0.150747\n",
              "2     Regression logistique (RL)              4.115931       0.073569\n",
              "3         Arbre de decision (AD)             22.159051       0.027639"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67a0d00e-2691-46b5-b512-8aed6e0e5f51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithme</th>\n",
              "      <th>Temps d'entrainement</th>\n",
              "      <th>Temps de test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes Multinomial (NBM)</td>\n",
              "      <td>0.976525</td>\n",
              "      <td>0.061037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes Gaussien (NBG)</td>\n",
              "      <td>0.817354</td>\n",
              "      <td>0.150747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regression logistique (RL)</td>\n",
              "      <td>4.115931</td>\n",
              "      <td>0.073569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arbre de decision (AD)</td>\n",
              "      <td>22.159051</td>\n",
              "      <td>0.027639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67a0d00e-2691-46b5-b512-8aed6e0e5f51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67a0d00e-2691-46b5-b512-8aed6e0e5f51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67a0d00e-2691-46b5-b512-8aed6e0e5f51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "algo_noms = ['Naive Bayes Multinomial (NBM)', \n",
        "             'Naive Bayes Gaussien (NBG)'   , \n",
        "             'Regression logistique (RL)'   , \n",
        "             'Arbre de decision (AD)']\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Algorithme'            : algo_noms  ,\n",
        "    'Temps d\\'entrainement' : temps_train,\n",
        "    'Temps de test'         : temps_test\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jco5cNWpKYwg"
      },
      "source": [
        "**TODO: Analyser les résultats**\n",
        "\n",
        "- Que remarquez-vous concernant le temps d'entrainement ? (ordonner les algorithmes)\n",
        "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps d'entrainement)\n",
        "- Que remarquez-vous concernant le temps de test ? (ordonner les algorithmes)\n",
        "- Pourquoi nous avons eu ces résultats en se basant sur les algorithmes ? (discuter chaque algorithme vis-a-vis le temps de test)\n",
        "\n",
        "**Réponse**\n",
        "\n",
        "- Concernant le temps d'entraînement, nous remarquons que l'algorithme le plus rapide estNaive Bayes Gaussien (NBG)\t, suiviNaive Bayes Multinomial (NBM)\t\t, la Regression logistique (RL), puis enfin Arbre de decision (AD)\t qui est le plus lent.\n",
        "- Ces résultats sont attendus car chaque algorithme a une complexité différente en termes de temps d'entraînement. Les algorithmes de type Bayesien, tels que le Naive Bayes Gaussien et le Naive Bayes Multinomial, sont généralement plus rapides à entraîner car ils ont une complexité linéaire en fonction de la taille des données d'entraînement. La Régression logistique a une complexité légèrement supérieure car elle doit optimiser des coefficients pour ajuster le modèle aux données. Enfin, l'Arbre de décision a une complexité plus élevée car il doit chercher la meilleure partition pour chaque nœud de l'arbre, ce qui peut être très coûteux pour les grands ensembles de données.\n",
        "- Concernant le temps de test, nous remarquons que l'algorithme le plus rapide est l'arbre de décision (AD) avec un temps de test de 0.027639 secondes, suivi par Naive Bayes Multinomial (NBM) avec 0.061037 secondes, la Regression logistique (RL) avec 0.073569 secondes, et enfin Naive Bayes Gaussien (NBG) avec 0.150747 secondes.\n",
        "- Ces résultats s'expliquent en partie par les caractéristiques de chaque algorithme. L'Arbre de décision (AD) est un algorithme relativement simple qui consiste à diviser de manière récursive les données en fonction de seuils sur les différentes variables, ce qui rend son temps de test très rapide. De même, la Régression logistique (RL) est également un algorithme assez simple qui peut être résolu de manière analytique, ce qui en fait un algorithme rapide en temps de test.En revanche, les deux algorithmes de Naive Bayes nécessitent de calculer des probabilités, ce qui peut être plus coûteux en temps de calcul. Le Naive Bayes Multinomial (NBM) nécessite de calculer les probabilités d'apparition de chaque mot dans chaque catégorie, tandis que le Naive Bayes Gaussien (NBG) nécessite de calculer les moyennes et les variances de chaque variable pour chaque catégorie. Ces calculs peuvent être plus coûteux en temps de test que les algorithmes simples comme l'AD ou la RL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKTaBIGuKYwh"
      },
      "source": [
        "#### II.3.2. Qualité de prédiction\n",
        "\n",
        "Comment chaque algorithme performe sur le dataset de test dans le cas de détection de spams (spam: est la classe positive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Fcht2T8NKYwh",
        "outputId": "ff37426d-1765-4763-f3df-35bc039aa521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Algorithme    Rappel  Precision\n",
              "0  Naive Bayes Multinomial (NBM)  0.927711   0.987179\n",
              "1     Naive Bayes Gaussien (NBG)  0.891566   0.616667\n",
              "2     Regression logistique (RL)  0.855422   0.986111\n",
              "3         Arbre de decision (AD)  0.825301   0.907285"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3ab1eb8-ea25-4731-b93b-826bb8cec00e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithme</th>\n",
              "      <th>Rappel</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes Multinomial (NBM)</td>\n",
              "      <td>0.927711</td>\n",
              "      <td>0.987179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes Gaussien (NBG)</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.616667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Regression logistique (RL)</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.986111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arbre de decision (AD)</td>\n",
              "      <td>0.825301</td>\n",
              "      <td>0.907285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3ab1eb8-ea25-4731-b93b-826bb8cec00e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3ab1eb8-ea25-4731-b93b-826bb8cec00e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3ab1eb8-ea25-4731-b93b-826bb8cec00e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pd.DataFrame({\n",
        "    'Algorithme' : algo_noms,\n",
        "    'Rappel'     : rappel   ,\n",
        "    'Precision'  : precision\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ley9mf6ZKYwi"
      },
      "source": [
        "**TODO: Analyser les résultats**\n",
        "\n",
        "On remarque que Naive Bayes surpasse la régression logistique pour la détection de spams. \n",
        "- Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème ?\n",
        "- Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires ?\n",
        "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature des deux algorithmes ?\n",
        "- Pourquoi le modèle gaussien est moins performant que le multinomial en se basant sur la nature du probleme/donnees ?\n",
        "\n",
        "**Réponse**\n",
        "\n",
        "- \n",
        "Non, cela ne prouve pas que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel problème.\n",
        "- Oui, Naive Bayes peut donner de meilleurs résultats que les autres algorithmes sur des problèmes similaires\n",
        "- Le modèle gaussien est moins performant que le modèle multinomial dans la détection de spams car il suppose que les variables d'entrée suivent une distribution normale. Cependant, dans le cas de la détection de spams, les variables d'entrée sont des fréquences d'apparition de mots, ce qui ne suit pas une distribution normale. Le modèle gaussien ne peut donc pas capturer toutes les nuances des données et ne convient pas bien pour ce type de problème.En revanche, le modèle multinomial prend en compte la fréquence d'apparition des mots, ce qui est plus adapté pour ce type de données.\n",
        "-  Les modèles de type multinomial sont plus adaptés pour les données discrètes, comme les données de texte dans ce cas, où chaque mot peut être considéré comme une variable discrète représentant la fréquence d'apparition d'un mot dans un message. En revanche, le modèle gaussien suppose que les variables sont continues et suivent une distribution gaussienne, ce qui est moins adapté aux données de texte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kO3Ij56KYwj",
        "outputId": "6ee361c8-0ded-445e-882c-bd2037157326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  _____    __                                              _               \n",
            " |_   _|  / _|                                            | |              \n",
            "   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \n",
            "   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \n",
            "  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \n",
            " |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \n",
            "                   __/ |                     __/ |                         \n",
            "                  |___/                     |___/                          \n",
            "  _     _       _            __                                            \n",
            " | |   | |     (_)          / _|                 _                         \n",
            " | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \n",
            " | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \n",
            " | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \n",
            "  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \n",
            "                                                |/                         \n",
            "                                                                           \n",
            "                                                                           \n",
            "                                                                           \n",
            "  _   _    ___    _   _      __ _   _ __    ___                            \n",
            " | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \n",
            " | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \n",
            "  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \n",
            "   __/ |                                                                   \n",
            "  |___/                                                                    \n",
            "                    _                                                __    \n",
            "                   | |                                            _  \\ \\   \n",
            "  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \n",
            " | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \n",
            " | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \n",
            " |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \n",
            "                                                                     /_/   \n",
            "                                                                           \n"
          ]
        }
      ],
      "source": [
        "print(\"  _____    __                                              _               \")\n",
        "print(\" |_   _|  / _|                                            | |              \")\n",
        "print(\"   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \")\n",
        "print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
        "print(\"  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \")\n",
        "print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
        "print(\"                   __/ |                     __/ |                         \")\n",
        "print(\"                  |___/                     |___/                          \")\n",
        "print(\"  _     _       _            __                                            \")\n",
        "print(\" | |   | |     (_)          / _|                 _                         \")\n",
        "print(\" | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \")\n",
        "print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
        "print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
        "print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
        "print(\"                                                |/                         \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"  _   _    ___    _   _      __ _   _ __    ___                            \")\n",
        "print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
        "print(\" | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \")\n",
        "print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
        "print(\"   __/ |                                                                   \")\n",
        "print(\"  |___/                                                                    \")\n",
        "print(\"                    _                                                __    \")\n",
        "print(\"                   | |                                            _  \\ \\   \")\n",
        "print(\"  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \")\n",
        "print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
        "print(\" | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \")\n",
        "print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n",
        "print(\"                                                                     /_/   \")\n",
        "print(\"                                                                           \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV9oHqvPKYwj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}